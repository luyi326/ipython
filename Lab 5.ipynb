{
 "metadata": {
  "name": "",
  "signature": "sha256:de897659dc6a8dda59c73ccca2afce6de3251cef5fce0148dc0058ea545bc3b5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Lab 5: Statistics, Curve-fitting, Proabaility Distributions</h1>\n",
      "<h2>Physics 102 - Fall 2014</h2>\n",
      "\n",
      "<h4>Learning Objectives:</h4>\n",
      "At the end of this lab, you will be able to:\n",
      "<ul>\n",
      "    <li>Calculate the mean, median, mode, variance, standard deviation, range, variance, skewness and, kurtosis of a sample using Python.</li>\n",
      "    <li>Explain how minimizing residuals is used in curve-fitting.</li>\n",
      "    <li>Use built-in Python routines for curve-fitting.</li>\n",
      "    <li>Create a probability distribution from a set of data.</li>\n",
      "</ul> "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Statistics</h3>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Statistics is a set of concepts, rules, and procedures that help us to organized numerical information, analyze numerical information, and make informed decisions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "data = np.array([4.48, 4.34, 4.51, 7.14, 5.02, 3.68, 2.65, 6.47, 4.34, 6.00,\n",
      "        3.76, 3.62, 5.44, 7.54, 3.81, 5.21, 4.49, 4.06, 6.19])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Measures of Center</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are three common statistical measures of center: mean, median and mode. Numpy contains built-in functions for computing the mean, and median. The typical symbol used for the mean is $\\mu$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.mean(data) # Mean\n",
      "\n",
      "print np.median(data) # Median"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get the mode we need to import the stats library. The stats library contains several other statistical tools that we will use in this lab. See  for the complete description of the stats package see the <a href='http://docs.scipy.org/doc/scipy-0.14.0/reference/stats.html'>documentation</a>. Mode returns a tuple containing the mode along with the number of occurances."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import stats\n",
      "\n",
      "print stats.mode(data) # Mode"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Measures of Spread</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we know the center we might want to know how far the data spreads from the center. Common measures of spread are range, variance, and standard deviation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The range is just the difference between the maximum and the minimum"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_range = data.max() - data.min()\n",
      "\n",
      "print data_range"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The variance is defined by\n",
      "\n",
      "$$ \\frac{1}{n}\\sum_{i=1}^n (x_i-\\mu)^2$$\n",
      "\n",
      "Where $n$ is the number of data points $x_i$, and $\\mu$ is the mean of the data set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.var(data) # Variance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The standard deviation is the square root of the variance\n",
      "\n",
      "$$\\sigma = \\sqrt{ \\frac{1}{n}\\sum_{i=1}^n (x_i-\\mu)^2 }$$\n",
      "\n",
      "The typical symbol used for standard deviation is $\\sigma$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.std(data) # Standard deviation\n",
      "\n",
      "print np.sqrt(np.var(data)) # Square-root of the variance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Measures of Shape</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The formula for variance suggests the possibility of different statistical measures of the form:\n",
      "\n",
      "$$ \\frac{1}{n}\\sum_{i=1}^n (x_i-\\mu)^M$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are called the central moments and Python has methods for calculating the central moments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stats.moment(data, 2) # Second moment\n",
      "\n",
      "print stats.moment(data, 3) # Third moment\n",
      "\n",
      "print stats.moment(data, 4) # Fourth moment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These moments describe the data and the shape of the data distribution. In order to compare the shape of different data sets, the central moments are typically divided by the standard deviation to the same power as the moment.\n",
      "\n",
      "$$ \\dfrac{\\frac{1}{n}\\sum_{i=1}^n (x_i-\\mu)^M}{\\sigma^M} $$\n",
      "\n",
      "Note: The normalized moments measured this way are unitless and can be compared across data sets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stats.moment(data, 2)/np.std(data)**2 # Second normalized moment\n",
      "\n",
      "print stats.moment(data, 3)/np.std(data)**3 # Third normalized moment\n",
      "\n",
      "print stats.moment(data, 4)/np.std(data)**4 # Fourth normalized moment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The normalized third and fourth moments are named. The normalized third moment is called the skewness and gives a measure of how symmetrical a data set is."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stats.moment(data, 3)/np.std(data)**3 # Third normalized moment\n",
      "\n",
      "print stats.skew(data) # Skewness"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The normalized forth moment is called the kurtosis. Typically this is given as the excess kurtosis where 3 is the kurtosis of a gaussian/normal distribution. The kurtosis gives a measure of how pointed a distribution is."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print stats.moment(data, 4)/np.std(data)**4 - 3 # Third normalized moment minus 3\n",
      "\n",
      "print stats.kurtosis(data) # Skewness"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These measures provide simple descriptions of a data set and can be used to compare different sets of data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Curve-fitting</h3>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the major goals of phyiscs is finding mathematical representations of physical phenomenon. This means we want to find functions that describe the physical world. Typically these functions involve parmeters that represent physical quanties. Take for example the force exerted by a spring. We can use a simple linear spring model.\n",
      "\n",
      "$$ F = -k x $$\n",
      "\n",
      "The force $F$ and the displacement $x$ are things that we can measure. The model gives a relationship between $F$ and $x$ and relates them using the spring constant $k$. If we measure a set of $(x, F)$ data we can use curve fitting to determine the best value the use for $k$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "data_x = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n",
      "data_y = np.array([3.03, 5.93,   9.00,  11.98,  14.93, 18.03117516])\n",
      "\n",
      "y_1 = 1*data_x\n",
      "y_2 = 2*data_x\n",
      "y_3 = 3*data_x\n",
      "y_4 = 4*data_x\n",
      "\n",
      "plt.plot(data_x, data_y, marker='*', lw=0, label='data')\n",
      "plt.plot(data_x, y_1, label='k=1')\n",
      "plt.plot(data_x, y_2, label='k=2')\n",
      "plt.plot(data_x, y_3, label='k=3')\n",
      "plt.plot(data_x, y_4, label='k=4')\n",
      "plt.legend(loc=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rather than plotting a bunch of curves and guessing which one fits the data the best, we need a way to objectively determine which curve is the best. This is what curve-fitting does for us, it gives us an objective method for determining which parameter values we should use in the model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is where the idea of distance discussed in Lab 1 comes in to play. Once a suitable distance is chosen, the curve that is closest to the data is the best-fit curves and gives the parameters that best describe the data. Stated this way, curve-fitting is simply a minimization problem, mimimizing the distance between a function and a set of data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A typical distance is the sum of the square of the residuals\n",
      "\n",
      "$$ d = \\sum_i \\left(y_i - f\\left(x_i\\right)\\right)^2$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the example shown, we can think of our function as having the parameter $k$ as a variable\n",
      "\n",
      "$$f(x, k) = -k,x $$\n",
      "\n",
      "And the distance becomes a function of $k$ only.\n",
      "\n",
      "$$ d(k) = \\sum_i \\left(y_i - f\\left(x_i, k\\right)\\right)^2$$\n",
      "\n",
      "We can minimize the distance by taking a derivative, setting the derivative equal to zero, and solving for the value of $k$ that minimizes the distance.\n",
      "\n",
      "$$\\frac{\\partial d(k)}{\\partial k} = 0$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the example used above this becomes\n",
      "\n",
      "$$ \\frac{\\partial d(k)}{\\partial k} = \\sum_i 2\\left(y_i + k x_i\\right)x_i = 0$$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If the model has multiple parameters, the best fit can be obtained by minimizing the partial derivatives with respect to each parameter\n",
      "\n",
      "$$\\frac{\\partial d(\\alpha, \\beta, \\gamma)}{\\partial \\alpha} = 0$$\n",
      "\n",
      "$$\\frac{\\partial d(\\alpha, \\beta, \\gamma)}{\\partial \\beta} = 0$$\n",
      "\n",
      "$$\\frac{\\partial d(\\alpha, \\beta, \\gamma)}{\\partial \\gamma} = 0$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are many techniques for finding the minimium distance numerically. Rather than spending two labs on minimization methods, it is enough for you to understand in a very abstract sense what is going on when you use methods and functions in Python. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Linear Fit</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a simple linear fit $y = m x + b$, we can use the linear regression routine in the stats package."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_x = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n",
      "data_y = np.array([3.03, 5.93,   9.00,  11.98,  14.93, 18.03117516])\n",
      "\n",
      "slope, intercept, r_value, p_value, std_err = stats.linregress(data_x, data_y)\n",
      "\n",
      "print 'The best-fit slope is: {0}'.format(slope)\n",
      "print 'The best-fit intercept is: {0}'.format(intercept)\n",
      "print 'The R value is: {0}'.format(r_value)\n",
      "print 'The P value intercept is: {0}'.format(p_value)\n",
      "print 'The best-fit slope with error is: {0} plus/minus {1}'.format(slope, std_err)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The R value gives a measure of how linear the data is. The P value gives a measure of how good the fit is, the smaller the value the better the fit. The standard error currently gives the error on the slope (note that this is different than the typical standard error)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Other Functions</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The SciPy package has a module that can be used to fit any curve."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.optimize import curve_fit\n",
      "\n",
      "def func(x, a, b, c):\n",
      "    return a * np.exp(-b * x) + c\n",
      "\n",
      "xdata = np.linspace(0, 4, 50)\n",
      "y = func(xdata, 2.5, 1.3, 0.5)\n",
      "ydata = y + 0.2 * np.random.normal(size=len(xdata))\n",
      "\n",
      "popt, pcov = curve_fit(func, xdata, ydata)\n",
      "\n",
      "print popt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a complete description see http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.optimize.curve_fit.html."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy.optimize import curve_fit\n",
      "def func(x, a, b, c):\n",
      "    return a * np.exp(-b * x) + c\n",
      "\n",
      "xdata = np.linspace(0, 4, 50)\n",
      "y = func(xdata, 2.5, 1.3, 0.5)\n",
      "ydata = y + 0.2 * np.random.normal(size=len(xdata))\n",
      "\n",
      "popt, pcov = curve_fit(func, xdata, ydata)\n",
      "\n",
      "print popt\n",
      "\n",
      "y_fit = func(xdata, *popt) # The *popt passes the arguments to func\n",
      "\n",
      "plt.plot(xdata, ydata, marker='*', lw=0, label='Data')\n",
      "plt.plot(xdata, y_fit, label='Fit')\n",
      "plt.legend(loc=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is really a really powerful module and allows you to fit nearly any curve to nearly any set of data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def square(x, A):\n",
      "    return A*x**2\n",
      "\n",
      "xdata = np.linspace(0, 4, 50)\n",
      "y = square(xdata, 1.3)\n",
      "ydata = y + 0.2 * np.random.normal(size=len(xdata))\n",
      "\n",
      "popt, pcov = curve_fit(square, xdata, ydata)\n",
      "\n",
      "y_fit = square(xdata, *popt) # The *popt passes the arguments to func\n",
      "\n",
      "plt.plot(xdata, ydata, marker='*', lw=0, label='Data')\n",
      "plt.plot(xdata, y_fit, label='Fit')\n",
      "plt.legend(loc=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Histograms and Probability Distributions</h3> "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are some physical quantities, like the size of earthquakes, for which individual events do not fall on nice functions, but if we look at a collection of events, there are patterns. We can ask questions of how many magnitude 5 earthquakes occur and how do the number of earthquakes with magnitude 5 compare to the number of earthquakes with magnitude 4. This is where statistics becomes really powerful, when systems no longer appear to be deterministic but behaves probabilistically. The simplest question you can ask about a probabalistic system is how many times a certain event happens. How many people have birthdays in December? How many fish are at least 12 inches long? To visualize this type of information we use histograms."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Histograms are visualizations of a distribution of a ster of data. Distributions are just what we described, how many with a certain property. For more information on histograms, see <a href=\"http://en.wikipedia.org/wiki/Histogram\">Wikipedia</a>. Numpy makes it easy to make histograms out of numerical data. First we need to get some data. For this example we will use all the earthquakes in the world during the past year with a magnitude 4.0 or grater."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "\n",
      "raw_data = np.genfromtxt('earthquake_data.txt', dtype={'names': ('DateTime', 'Latititue', 'Longitude', 'Depth', 'Magnitude' ),'formats': (datetime.datetime, float, float, float, float)}, delimiter=',', skiprows=1, usecols=(4,))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we have the data, we ask numpy to create a histogram of the data with 8 bins. Numpy looks and the max and the min of the data and creates 8 equally spaced bins. The histogram function returns a tuple containing the counts in each bin along with the bin edges."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts, bin_edges = np.histogram(raw_data['Magnitude'], bins=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The counts and bin edges is a classic case of the <a href=\"http://en.wikipedia.org/wiki/Off-by-one_error\">fence post problem</a>. To create a fence with n panels you need n+1 posts. To get n bins, we need n+1 bin edges. In order to plot the data, we need to create an array containing the bin centers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take all bin edges except the last one, and add half the distance between the first two edges\n",
      "\n",
      "bin_centers = bin_edges[:-1]+(bin_edges[1]-bin_edges[0])/2.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can plot the counts as bars like a typical histogram."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.bar(bin_centers, counts, color='cyan')\n",
      "plt.xlabel('Magnitude')\n",
      "plt.ylabel('Counts')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or we can just plot it as a line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(bin_centers, counts)\n",
      "plt.xlabel('Magnitude')\n",
      "plt.ylabel('Counts')\n",
      "plt.xscale('log')\n",
      "plt.yscale('log')\n",
      "plt.xlim((5,9))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want to use specific bin edges we can specify them as a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bin_edges = [5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "\n",
      "counts, bin_edges = np.histogram(raw_data['Magnitude'], bins=bin_edges)\n",
      "\n",
      "bin_centers = bin_edges[:-1]+(bin_edges[1]-bin_edges[0])/2.0\n",
      "\n",
      "plt.plot(bin_centers, counts)\n",
      "plt.xlabel('Magnitude')\n",
      "plt.ylabel('Counts')\n",
      "plt.xscale('log')\n",
      "plt.yscale('log')\n",
      "plt.xlim((5,10))\n",
      "plt.ylim((0.1, 10000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Probability Density</h4>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While histograms are very helpful, we are often more concerned about the shape of the histogram than we are with the actual counts. We often want to compare two different histograms where the number of data points in each historgram is different. In order to do this, we typically convert histograms into probability densities. The difference between a histogram and a probability densisty is that when we sum over a histogram, we get the total number of events. When we sum over a probability density, we get one. In this regard the probability density is a normalized histogram. To get a probability density, we just add the keyword argument <code>density=True</code> to the historgram function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bin_edges = [5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "\n",
      "counts, bin_edges = np.histogram(raw_data['Magnitude'], bins=bin_edges, density=True)\n",
      "\n",
      "bin_centers = bin_edges[:-1]+(bin_edges[1]-bin_edges[0])/2.0\n",
      "\n",
      "plt.plot(bin_centers, counts)\n",
      "plt.xlabel('Magnitude')\n",
      "plt.ylabel('Counts')\n",
      "plt.xscale('log')\n",
      "plt.yscale('log')\n",
      "plt.xlim((5,10))\n",
      "plt.ylim((0.0001, 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We typically think of the probability density as a probability distribution $P\\left(x\\right)$ which we can integrate over.\n",
      "\n",
      "$$ 1 = \\int P\\left(x\\right) \\mathrm{d} x $$\n",
      "\n",
      "We can convert the integral to a sum in the discrete case.\n",
      "\n",
      "$$ 1 = \\sum_i P_i \\Delta x $$\n",
      "\n",
      "Where $P_i$ is the $i$th probability densisty and $\\Delta x$ is the bin width."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bin_width = (bin_edges[1]-bin_edges[0])\n",
      "\n",
      "(counts*bin_width).sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most commonly used probability density function is the gaussian or normal distribution.\n",
      "\n",
      "$$\\LARGE G(x, \\mu, \\sigma) = \\frac{1}{ \\sigma \\sqrt{2 \\pi}} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The gaussian or normal distribution is sometimes called the bell-curve. A gaussian is defined by two properties, the mean $\\mu$ and the standard deviation $\\sigma$. In a gaussian distribution, probability is concentrated around the mean."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.array([0., 0.1010101, 0.2020202, 0.3030303, 0.4040404,\n",
      "   0.50505051, 0.60606061, 0.70707071, 0.80808081, 0.90909091,\n",
      "   1.01010101, 1.11111111, 1.21212121, 1.31313131, 1.41414141,\n",
      "   1.51515152, 1.61616162, 1.71717172, 1.81818182, 1.91919192,\n",
      "   2.02020202, 2.12121212, 2.22222222, 2.32323232, 2.42424242,\n",
      "   2.52525253, 2.62626263, 2.72727273, 2.82828283, 2.92929293,\n",
      "   3.03030303, 3.13131313, 3.23232323, 3.33333333, 3.43434343,\n",
      "   3.53535354, 3.63636364, 3.73737374, 3.83838384, 3.93939394,\n",
      "   4.04040404, 4.14141414, 4.24242424, 4.34343434, 4.44444444,\n",
      "   4.54545455, 4.64646465, 4.74747475, 4.84848485, 4.94949495,\n",
      "   5.05050505, 5.15151515, 5.25252525, 5.35353535, 5.45454545,\n",
      "   5.55555556, 5.65656566, 5.75757576, 5.85858586, 5.95959596,\n",
      "   6.06060606, 6.16161616, 6.26262626, 6.36363636, 6.46464646,\n",
      "   6.56565657, 6.66666667, 6.76767677, 6.86868687, 6.96969697,\n",
      "   7.07070707, 7.17171717, 7.27272727, 7.37373737, 7.47474747,\n",
      "   7.57575758, 7.67676768, 7.77777778, 7.87878788, 7.97979798,\n",
      "   8.08080808, 8.18181818, 8.28282828, 8.38383838, 8.48484848,\n",
      "   8.58585859, 8.68686869, 8.78787879, 8.88888889, 8.98989899,\n",
      "   9.09090909, 9.19191919, 9.29292929, 9.39393939, 9.49494949,\n",
      "   9.5959590, 9.6969697, 9.7979798, 9.8989899, 10.])\n",
      "\n",
      "y = np.array([1.53891973e-22,   1.13688438e-21,   8.06291600e-21,   5.48963507e-20,\n",
      "              3.58814776e-19,   2.25150411e-18,   1.35628386e-17,   7.84339244e-17,\n",
      "              4.35444492e-16,   2.32079704e-15,   1.18745463e-14,   5.83273696e-14,\n",
      "              2.75044688e-13,   1.24511549e-12,   5.41117418e-12,   2.25761018e-11,\n",
      "              9.04236094e-11,   3.47688419e-10,   1.28343570e-09,   4.54813670e-09,\n",
      "              1.54727820e-08,   5.05334336e-08,   1.58439956e-07,   4.76898681e-07,\n",
      "              1.37804384e-06,   3.82274643e-06,   1.01803664e-05,   2.60271629e-05,\n",
      "              6.38801245e-05,   1.50515138e-04,   3.40463151e-04,   7.39325267e-04,\n",
      "              1.54126206e-03,   3.08455792e-03,   5.92631697e-03,   1.09308101e-02,\n",
      "              1.93550948e-02,   3.29013530e-02,   5.36917694e-02,   8.41157223e-02,\n",
      "              1.26509210e-01,   1.82659647e-01,   2.53185358e-01,   3.36907022e-01,\n",
      "              4.30384918e-01,   5.27812335e-01,   6.21408974e-01,   7.02345833e-01,\n",
      "              7.62079015e-01,   7.93824502e-01,   7.93824502e-01,   7.62079015e-01,\n",
      "              7.02345833e-01,   6.21408974e-01,   5.27812335e-01,   4.30384918e-01,\n",
      "              3.36907022e-01,   2.53185358e-01,   1.82659647e-01,   1.26509210e-01,\n",
      "              8.41157223e-02,   5.36917694e-02,   3.29013530e-02,   1.93550948e-02,\n",
      "              1.09308101e-02,   5.92631697e-03,   3.08455792e-03,   1.54126206e-03,\n",
      "              7.39325267e-04,   3.40463151e-04,   1.50515138e-04,   6.38801245e-05,\n",
      "              2.60271629e-05,   1.01803664e-05,   3.82274643e-06,   1.37804384e-06,\n",
      "              4.76898681e-07,   1.58439956e-07,   5.05334336e-08,   1.54727820e-08,\n",
      "              4.54813670e-09,   1.28343570e-09,   3.47688419e-10,   9.04236094e-11,\n",
      "              2.25761018e-11,   5.41117418e-12,   1.24511549e-12,   2.75044688e-13,\n",
      "              5.83273696e-14,   1.18745463e-14,   2.32079704e-15,   4.35444492e-16,\n",
      "              7.84339244e-17,   1.35628386e-17,   2.25150411e-18,   3.58818734e-19,\n",
      "              5.48963507e-20,   8.06291600e-21,   1.13688438e-21,   1.53891973e-22])\n",
      "\n",
      "plt.plot(x, y)\n",
      "plt.title('Gaussian Distribution')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Exercies<h2>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This week we are going to look at some statistics and do some curve-fitting with real data. One common assumption in economics is that stock returns follow a gaussian probability distribution. We want to look at whether this is a good assumption."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Exercise 1</h3>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this exercise is to write a function which will automate the statistical analysis of the daily returns for a stock. The function should take the stock ticker as a string. It should return None, but should write the calculated quantities to file."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Your function should import the stock data from yahoo stocks for the given TICKER. You may assume the given ticker is valid. Once you have the stock data, you should calculate the daily (one trading day) returns using the open prices. These daily returns are the data we want analyze. You should compute the mean, standard deviation, skew, and kurtosis of the daily returns. You should write the computed values to a file with the name \"TICKER_daily_returns_stats.txt\". The file format should be:\n",
      "\n",
      "<code>\n",
      "Statistical Properties of Daily Returns For: TICKER\n",
      "\n",
      "Mean = ????\n",
      "Median = ????\n",
      "Standard Deviation = ????\n",
      "Skewness = ????\n",
      "Kurtosis = ????\n",
      "</code>\n",
      "\n",
      "\n",
      "Where \"????\" are replaced with the values calculated in your function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Exercise 2</h3>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a simple exercise which you will need to complete Exercise 3. The goal of this exercise is to write a function which takes three parameters: a value $x$, a mean $\\mu$, and a standard deviation $\\sigma$ (all as floats). Your function should caluculate the probability density at the value $x$ for a gaussian with mean $\\sigma$, and standard deviation $\\mu$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Exercise 3</h>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this exercise is to write a function which will fit a gaussian probability distribution to the distribution of daily returns for a sock. The function should take the stock sticker as a string. It should return None, but should save a plot to file."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Your function should import the stock data from yahoo stocks for the given TICKER. You may assume the ticker is valid. Once you have the stock data, you should calculate the daily (one trading day) returns using the open prices. Rather than looking at the returns as a time series, we are going to look at the distribution of returns. You should create a histogram of the returns using \"density=True\" and 200 bins. This will give you a probability distribution for the returns."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You should fit a gaussian to your probability distribution using the bin centers as the x-data and the probability distribution as the y-data. You should obtain the best-fit values for the mean and standard deviation. Using this best-fit gaussian, your function should create a plot of both the probability distribution and the best-fit gaussian. The plot title should be the TICKER, and you should label the axes. Additionally, include a legend labeling the return data and the gaussian. Also, somewhere on the plot, you should display the best-fit mean and standard deviation to three decimal points. Your function should save the plot to \"TICKER_gaussian_fit.pdf\". An example plot will be provided."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}